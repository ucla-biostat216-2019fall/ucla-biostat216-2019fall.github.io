{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimization and Multivariate Calculus\n",
    "\n",
    "We will use optimization to motivate the development of multivariate calculus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multivariate calculus\n",
    "\n",
    "- For a sufficiently smooth scalar function $f: \\mathbb{R} \\mapsto \\mathbb{R}$, we have the second order Taylor approximation:  \n",
    "$$\n",
    "f(x + \\Delta x) \\approx f(x) + \\Delta x \\frac{d}{dx}f(x) + \\frac 12 (\\Delta x)^2 \\frac{d^2}{dx^2}f(x).\n",
    "$$\n",
    "\n",
    "- TODO: graph\n",
    "\n",
    "- To generalize to a multivariate function $f: \\mathbb{R}^n \\mapsto \\mathbb{R}$, we need notations:  \n",
    "    - **Gradient**:\n",
    "$$\n",
    "\\nabla f(\\mathbf{x}) = \\begin{pmatrix}\n",
    "\\frac{\\partial}{\\partial x_1} f(\\mathbf{x}) \\\\\n",
    "\\vdots \\\\\n",
    "\\frac{\\partial}{\\partial x_n} f(\\mathbf{x})\n",
    "\\end{pmatrix}.\n",
    "$$  \n",
    "    - **Hessian**:\n",
    "$$\n",
    "H(\\mathbf{x}) = \\nabla^2 f(\\mathbf{x}) = \\begin{pmatrix}\n",
    "\\frac{\\partial^2}{\\partial x_1^2} f(\\mathbf{x}) & \\cdots & \\frac{\\partial^2}{\\partial x_1 \\partial x_n} f(\\mathbf{x}) \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial^2}{\\partial x_n \\partial x_1} f(\\mathbf{x}) & \\cdots & \\frac{\\partial^2}{\\partial x_n^2} f(\\mathbf{x})\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "\n",
    "- Example: TODO.\n",
    "\n",
    "- For a sufficiently smooth multivariate function $f: \\mathbb{R}^n \\mapsto \\mathbb{R}$, we have Taylor approximation:  \n",
    "$$\n",
    "f(\\mathbf{x} + \\Delta \\mathbf{x}) \\approx f(\\mathbf{x}) + \\nabla f(\\mathbf{x})' \\Delta \\mathbf{x} + \\frac 12 \\Delta \\mathbf{x}' [\\nabla^2 f(\\mathbf{x})] \\Delta \\mathbf{x}.\n",
    "$$\n",
    "\n",
    "- For a vector function $f: \\mathbb{R}^{n} \\mapsto \\mathbb{R}^m$\n",
    "$$\n",
    "f(\\mathbf{x}) = \\begin{pmatrix} f_1(\\mathbf{x}) \\\\ \\vdots \\\\ f_m(\\mathbf{x}) \\end{pmatrix},\n",
    "$$\n",
    "the $m \\times n$ **Jacobian matrix** is\n",
    "$$\n",
    "\\mathbf{J} = \\begin{pmatrix} \\nabla f_1' \\\\ \\vdots \\\\ \\nabla f_m' \\end{pmatrix} = \\begin{pmatrix}\n",
    "\\frac{\\partial f_1}{\\partial x_1} & \\cdots & \\frac{\\partial f_1}{\\partial x_n} \\\\\n",
    "\\vdots & \\ddots & \\vdots \\\\\n",
    "\\frac{\\partial f_m}{\\partial x_1} & \\cdots & \\frac{\\partial f_m}{\\partial x_n}\n",
    "\\end{pmatrix}.\n",
    "$$\n",
    "The **Jacobian** is the determant of $\\mathbf{J}$ and appears in the multi-dimensional integrals.\n",
    "\n",
    "Later we will develop chain rule for the vector and matrix functions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimization and optimality conditions\n",
    "\n",
    "- Optimization aims to minimize a multivariate function $f: \\mathbb{R}^n \\mapsto \\mathbb{R}$ possibly subject to certain constraints. Possible constrains include  \n",
    "    - Linear constraints: $\\mathbf{A} \\mathbf{x} = \\mathbf{b}$.  \n",
    "    - Inequality constraints: $\\mathbf{x} \\ge \\mathbf{0}$.  \n",
    "    - Integer constraints: Each $x_i$ is either 0 or 1.\n",
    "    \n",
    "- Statisticians often talk about _maximization_, because of the maximum likelihood estimation (MLE). Note maximizing $f$ is same as minimizing $-f$. \n",
    "\n",
    "- For unconstrained optimization of a scalar function $f$, we know\n",
    "    - the necessary condition for a point $x$ to be a local minimum is $\\frac{d}{dx} f(x)= 0$.  \n",
    "    - a sufficient condition for a strict local minimum is (1) $\\frac{d}{dx} f(x) = 0$ and (2) $\\frac{d^2}{dx^2} f(x) > 0$.  \n",
    "    These are called the **optimality conditions**.  \n",
    "    \n",
    "- Similarly for unconstrained optimization of a multivariate function $f: \\mathbb{R}^n \\mapsto \\mathbb{R}$,\n",
    "    - the necessary condition for a point $\\mathbf{x}$ to be a local minimum is\n",
    "$$\n",
    "\\nabla f(\\mathbf{x}) = \\mathbf{0}_n.\n",
    "$$\n",
    "    - a sufficient condition for a strict local minimum is\n",
    "$$\n",
    "\\nabla f(\\mathbf{x}) = \\mathbf{0}_n\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\nabla^2 f(\\mathbf{x}) \\succ \\mathbf{O}_{n \\times n}.\n",
    "$$\n",
    "\n",
    "- A body of work in optimization is to generalize these optimality conditions to the constrained case."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convexity\n",
    "\n",
    "- Convexity plays a key role in optimization. \n",
    "\n",
    "    - A **convex set $\\mathcal{K}$**: If $\\mathbf{x}, \\mathbf{y} \\in \\mathcal{K}$, then the line from $\\mathbf{x}$ to $\\mathbf{y}$ $\\{\\alpha \\mathbf{x} + (1 - \\alpha) \\mathbf{y}: \\alpha \\in [0, 1]\\} \\subseteq \\mathcal{K}$.  \n",
    "    - A **convex function $f$**: \n",
    "$$\n",
    "f(\\alpha \\mathbf{x} + (1 - \\alpha) \\mathbf{y}) \\le \\alpha f(\\mathbf{x}) + (1 - \\alpha) f(\\mathbf{y})\n",
    "$$\n",
    "for all $\\mathbf{x}, \\mathbf{y}$ and $\\alpha \\in (0, 1)$.   \n",
    "    - A **strictly convex function** satisifies above definition but replacing $\\le$ by $<$.  \n",
    "    - A **convex function $f$** (alternative definition): The set of points on and above the graph of $f$, $\\{(\\mathbf{x},y): f(\\mathbf{x}) \\le y\\}$, is convex.  \n",
    "    - A **smooth and convex $f$**: $f(\\mathbf{x}) \\ge f(\\mathbf{y}) + \\nabla f(\\mathbf{y})' (\\mathbf{x} - \\mathbf{y})$ for all $\\mathbf{x}, \\mathbf{y}$. The function $f$ sits above its tangent lines.  \n",
    "    \n",
    "- TODO: A convex function sits between its tangent lines and its chords.    \n",
    "\n",
    "- TODO: graph of convex and nonconvex sets/functions.\n",
    "    \n",
    "- Examples: $f_1(x) = ax + b$, $f_2(x) = x^2$, and $f_3(x) = \\max(f_1(x), f_2(x))$.\n",
    "\n",
    "- **Intersection of convex sets is convex.**\n",
    "\n",
    "- **The maximum of two or more convex functions is always convex.**  \n",
    "\n",
    "    Proof: Let $f(\\mathbf{x}) = \\sup_{i \\in \\mathcal{I}} f_i (\\mathbf{x})$. Then\n",
    "$$\n",
    "f_i(\\alpha \\mathbf{x} + (1 - \\alpha) \\mathbf{y}) \\le \\alpha f_i(\\mathbf{x}) + (1 - \\alpha) f_i(\\mathbf{y}) \\le \\alpha f(\\mathbf{x}) + (1 - \\alpha) f(\\mathbf{y})\n",
    "$$\n",
    "for all $i \\in \\mathcal{I}$. Taking supremum over $i$ on the left hand side yields\n",
    "$$\n",
    "f(\\alpha \\mathbf{x} + (1 - \\alpha) \\mathbf{y}) \\le \\alpha f(\\mathbf{x}) + (1 - \\alpha) f(\\mathbf{y}).\n",
    "$$\n",
    "\n",
    "    Note the minimum of convex functions is usually not convex.\n",
    "    \n",
    "- The set of positive (semi)definite matrices is convex.\n",
    "\n",
    "- A twice differentiable function is convex if $\\nabla^2 f(\\mathbf{x}) \\succeq \\mathbf{O}_{n \\times n}$ at all $\\mathbf{x}$. It is strictly convex $\\nabla^2 f(\\mathbf{x}) \\succ \\mathbf{O}_{n \\times n}$ at all $\\mathbf{x}$.\n",
    "\n",
    "- **Convexity prevents two local minima.** For a convex function, any stationary point with $\\nabla f(\\mathbf{x}) = \\mathbf{0}$ is a global minimum."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimality conditions for constrained optimization\n",
    "\n",
    "- Example:\n",
    "\\begin{eqnarray*}\n",
    "    &\\text{minimize}& f(x_1,x_2) = x_1^2 + x_2^2 \\\\\n",
    "    &\\text{subject to}& a_1 x_1 + a_2 x_2 = b.\n",
    "\\end{eqnarray*}\n",
    "Define the **Lagrangian**\n",
    "$$\n",
    "L(x_1, x_2, \\lambda) = f(x_1, x_2) + \\lambda (a_1 x_1 + a_2 x_2 - b) = x_1^2 + x_2^2 + \\lambda (a_1 x_1 + a_2 x_2 - b),\n",
    "$$\n",
    "where $\\lambda$ is the **Lagrange multiplier**. Solve the equations\n",
    "\\begin{eqnarray*}\n",
    "\\frac{\\partial}{\\partial x_1} L &=& 2 x_1 + \\lambda a_1 \\\\\n",
    "\\frac{\\partial}{\\partial x_2} L &=& 2 x_2 + \\lambda a_2 \\\\\n",
    "\\frac{\\partial}{\\partial \\lambda} L &=& a_1 x_1 + a_2 x_2 - b\n",
    "\\end{eqnarray*}\n",
    "to get optimal $x_1$, $x_2$, and $\\lambda$:\n",
    "\\begin{eqnarray*}\n",
    "x_1^\\star &=& \\frac{a_1 b}{a_1^2 + a_2^2} \\\\\n",
    "x_2^\\star &=& \\frac{a_2 b}{a_1^2 + a_2^2} \\\\\n",
    "\\lambda^\\star &=& - \\frac{2b}{a_1^2 + a_2^2}\n",
    "\\end{eqnarray*}\n",
    "with optimal objective value\n",
    "$$\n",
    "(x_1^\\star)^2 + (x_2^\\star)^2 = \\frac{b^2}{a_1^2 + a_2^2}.\n",
    "$$\n",
    "We found **$-\\lambda^\\star$ is simply the derivative of the minimum cost with respect to the constraint level $b$**\n",
    "$$\n",
    "\\frac{d}{d b} \\left( \\frac{b^2}{a_1^2 + a_2^2} \\right) = \\frac{2b}{a_1^2 + a_2^2} = - \\lambda.\n",
    "$$\n",
    "\n",
    "- We generalize above example to the general problem of **minimizing a convex quadratic function with linear constraints**. For $\\mathbf{S} \\succ \\mathbf{0}$ and $\\mathbf{A} \\in \\mathbb{R}^{n \\times m}$,\n",
    "\\begin{eqnarray*}\n",
    "    &\\text{minimize}& \\frac 12 \\mathbf{x}' \\mathbf{S} \\mathbf{x} \\\\\n",
    "    &\\text{subject to}& \\mathbf{A}' \\mathbf{x} = \\mathbf{b}.\n",
    "\\end{eqnarray*}\n",
    "The **Lagrangian** function is\n",
    "$$\n",
    "L(\\mathbf{x}, \\boldsymbol{\\lambda}) = \\frac 12 \\mathbf{x}' \\mathbf{S} \\mathbf{x} + \\boldsymbol{\\lambda}' (\\mathbf{A}' \\mathbf{x} - \\mathbf{b}),\n",
    "$$\n",
    "where $\\boldsymbol{\\lambda} \\in \\mathbb{R}^m$ is the **Lagrange multipliers**. Solving equations\n",
    "\\begin{eqnarray*}\n",
    "    \\nabla_\\mathbf{x} L(\\mathbf{x}, \\boldsymbol{\\lambda}) &=& \\mathbf{S} \\mathbf{x} + \\mathbf{A} \\boldsymbol{\\lambda} = \\mathbf{0}_n \\\\\n",
    "    \\nabla_\\boldsymbol{\\lambda} L(\\mathbf{x}, \\boldsymbol{\\lambda}) &=& \\mathbf{A}' \\mathbf{x} - \\mathbf{b} = \\mathbf{0}_m,\n",
    "\\end{eqnarray*}\n",
    "or equivalently\n",
    "$$\n",
    "\\begin{pmatrix}\n",
    "\\mathbf{S} & \\mathbf{A} \\\\\n",
    "\\mathbf{A}' & \\mathbf{O}\n",
    "\\end{pmatrix} \\begin{pmatrix} \\mathbf{x} \\\\ \\boldsymbol{\\lambda} \\end{pmatrix} = \\begin{pmatrix} \\mathbf{0}_n \\\\ \\mathbf{b} \\end{pmatrix} \\quad \\quad (\\text{saddle point matrix or KKT matrix})\n",
    "$$\n",
    "yields the solution\n",
    "\\begin{eqnarray*}\n",
    "\\mathbf{x}^\\star &=& \\mathbf{S}^{-1} \\mathbf{A} (\\mathbf{A}' \\mathbf{S}^{-1} \\mathbf{A})^{-1} \\mathbf{b} \\\\\n",
    "\\boldsymbol{\\lambda}^\\star &=& - (\\mathbf{A}' \\mathbf{S}^{-1} \\mathbf{A})^{-1} \\mathbf{b}.\n",
    "\\end{eqnarray*}\n",
    "Further calculation shows the minimum cost\n",
    "$$\n",
    "f^\\star = \\frac 12 \\mathbf{b}' (\\mathbf{A}' \\mathbf{S}^{-1} \\mathbf{A})^{-1} \\mathbf{b}\n",
    "$$\n",
    "and the gradient of cost\n",
    "$$\n",
    "\\nabla_\\mathbf{b} f^\\star = (\\mathbf{A}' \\mathbf{S}^{-1} \\mathbf{A})^{-1} \\mathbf{b} = - \\boldsymbol{\\lambda}^\\star.\n",
    "$$\n",
    "\n",
    "- The saddle point matrix (or KKT matrix) has $n$ positive eigenvalues and $m$ negative eigenvalue. The Lagrangian function is convex in $\\mathbf{x}$ and concave in $\\boldsymbol{\\lambda}$.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: MLE of multivariate normal model\n",
    "\n",
    "Let $\\mathbf{y}_1, \\ldots, \\mathbf{y}_n$ be iid samples from a multivariate normal distribution $N(\\boldsymbol{\\mu}, \\boldsymbol{\\Omega})$. The log-likelihood is\n",
    "$$\n",
    "L(\\boldsymbol{\\mu}, \\boldsymbol{\\Omega}) = - \\frac n2 \\log \\det \\boldsymbol{\\Omega} - \\frac 12 \\sum_{i=1}^n (\\mathbf{y}_i - \\boldsymbol{\\mu})' \\boldsymbol{\\Omega}^{-1} (\\mathbf{y}_i - \\boldsymbol{\\mu}).\n",
    "$$\n",
    "We want to maximize $L(\\boldsymbol{\\mu}, \\boldsymbol{\\Omega})$ or minimize\n",
    "$$\n",
    "f(\\boldsymbol{\\mu}, \\boldsymbol{\\Omega}) = - L(\\boldsymbol{\\mu}, \\boldsymbol{\\Omega}) = \\frac n2 \\log \\det \\boldsymbol{\\Omega} + \\frac 12 \\sum_{i=1}^n (\\mathbf{y}_i - \\boldsymbol{\\mu})' \\boldsymbol{\\Omega}^{-1} (\\mathbf{y}_i - \\boldsymbol{\\mu}).\n",
    "$$\n",
    "The MLE is achieved by\n",
    "\\begin{eqnarray*}\n",
    "\\widehat{\\boldsymbol{\\mu}} &=& \\frac{\\sum_{i=1}^n \\mathbf{y}_i}{n} \\\\\n",
    "\\widehat{\\boldsymbol{\\Omega}} &=& \\frac{\\sum_{i=1}^n (\\mathbf{y}_i - \\hat{\\boldsymbol{\\mu}})(\\mathbf{y}_i - \\hat{\\boldsymbol{\\mu}})'}{n}.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "TODO: derivation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example: MLE of multinomial model\n",
    "\n",
    "Consider a multinomial experiment with $n$ trials and observed outcomes $n_1, \\ldots, n_m$ over $m$ categories. The maximum likelihood estimate (MLE) seeks maximizer of likelihood  \n",
    "$$\n",
    "L(p_1,\\ldots,p_m) = \\binom{n}{n_1 \\cdots n_m} \\prod_{i=1}^m p_i^{n_i}.\n",
    "$$\n",
    "To minimize the negative log-likelihood  \n",
    "$$\n",
    "\\log L(p_1,\\ldots,p_m) = \\log \\binom{n}{n_1 \\cdots n_m} + \\sum_{i=1}^m n_i \\log p_i\n",
    "$$\n",
    "subject to the constraint $p_1 + \\cdots + p_m = 1$, we find the statinary point of Lagrangian  \n",
    "$$\n",
    "L(p_1,\\ldots,p_m, \\lambda) = - \\log \\binom{n}{n_1 \\cdots n_m} - \\sum_{i=1}^m n_i \\log p_i + \\lambda \\left( \\sum_{i=1}^m p_i - 1 \\right).\n",
    "$$  \n",
    "Solving  \n",
    "$$\n",
    "\\frac{\\partial}{\\partial p_i} L = - \\frac{n_i}{p_i} + \\lambda = 0\n",
    "$$  \n",
    "gives  \n",
    "$$\n",
    "\\frac{n_i}{p_i} = \\lambda.\n",
    "$$  \n",
    "Combining with the constraint $\\sum_i p_i=1$ yields  \n",
    "\\begin{eqnarray*}\n",
    "p_i^\\star &=& \\frac{n_i}{n}, \\quad i=1,\\ldots,m, \\\\\n",
    "\\lambda^\\star &=& n.\n",
    "\\end{eqnarray*}\n",
    "Note the nonnegativity constraint is automatically satisfied."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Newton's method\n",
    "\n",
    "- We are looking for a point $\\mathbf{x}^\\star$ such that $\\nabla f(\\mathbf{x}^\\star) = \\mathbf{0}$. Multivariate calculus gives us a principled way to move towards such an $\\mathbf{x}^\\star$.\n",
    "\n",
    "- Second-order Taylor approximation to a function $f$ at current iterate $\\mathbf{x}^{(t)}$ says\n",
    "$$\n",
    "f(\\mathbf{x}^{(t)} + \\Delta \\mathbf{x}) \\approx f(\\mathbf{x}^{(t)}) + \\nabla f(\\mathbf{x}^{(t)})' \\Delta \\mathbf{x} + \\frac 12 \\Delta \\mathbf{x}' [\\nabla^2 f(\\mathbf{x}^{(t)})] \\Delta \\mathbf{x}.\n",
    "$$\n",
    "Which direction $\\Delta \\mathbf{x}$ shall we move from $\\mathbf{x}^{(t)}$? \n",
    "\n",
    "    Minimizing the quadratic approximation gives the **Newton direction**\n",
    "$$\n",
    "\\Delta \\mathbf{x}_{\\text{newton}} = - [\\nabla^2 f(\\mathbf{x}^{(t)})]^{-1} \\nabla f(\\mathbf{x}^{(t)}).\n",
    "$$\n",
    "\n",
    "- So the **Newton method** iterates according to\n",
    "$$\n",
    "\\mathbf{x}^{(t+1)} = \\mathbf{x}^{(t)} + \\Delta \\mathbf{x}_{\\text{newton}} = \\mathbf{x}^{(t)} - [\\nabla^2 f(\\mathbf{x}^{(t)})]^{-1} \\nabla f(\\mathbf{x}^{(t)}).\n",
    "$$\n",
    "\n",
    "- Quadratic convergence of Newton's method:\n",
    "$$\n",
    "\\|\\mathbf{x}^{(t+1)} - \\mathbf{x}^\\star\\| \\le C \\|\\mathbf{x}^{(t)} - \\mathbf{x}^\\star\\|^2.\n",
    "$$\n",
    "\n",
    "- Example: $f(x) = \\frac 13 x^3 - 4x$ with $\\nabla f(x) = x^2 - 4$ and $\\nabla^2 f(x) = 2x$. Newton's iterates are \n",
    "$$\n",
    "x^{(t+1)} = x^{(t)} - \\frac{x^{(t)2}-4}{2x^{(t)}} = \\frac{1}{2} \\left( x^{(t)} + \\frac{4}{x^{(t)}} \\right).\n",
    "$$\n",
    "Let's start from $x^{(0)}=2.5$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(x, x ^ 3 / 3 - 4x) = (2.05, -5.328291666666667)\n",
      "(x, x ^ 3 / 3 - 4x) = (2.000609756097561, -5.333332589652766)\n",
      "(x, x ^ 3 / 3 - 4x) = (2.0000000929222947, -5.333333333333316)\n",
      "(x, x ^ 3 / 3 - 4x) = (2.000000000000002, -5.333333333333334)\n",
      "(x, x ^ 3 / 3 - 4x) = (2.0, -5.333333333333334)\n"
     ]
    }
   ],
   "source": [
    "x = 2.5\n",
    "for iter in 1:5\n",
    "    x = 0.5 * (x + 4 / x)\n",
    "    @show x, x^3 / 3 - 4x\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "x^{(t+1)} - 2 = \\frac 12 \\left( x^{(t)} + \\frac{4}{x^{(t)}} \\right) - 2 = \\frac{1}{2x^{(t)}} \\left( x^{(t)} - 2 \\right)^2\n",
    "$$\n",
    "\n",
    "- In practice, the Newton's method may suffer from **instability**; the iterates may escape into infinities or a local maximum. Two remedies are needed:  \n",
    "    1. Use a positive definite matrix in the quadratic approximation (automatically satisfied by the Hessian of a convex function). \n",
    "    2. Line search (backtracking) to guarantee sufficient drop in the objective function\n",
    "$$\n",
    "f(\\mathbf{x}^{(t)} + s \\Delta \\mathbf{x}) \\le f(\\mathbf{x}^{(t)}) - \\alpha s \\Delta \\mathbf{x}' [\\nabla^2 f(\\mathbf{x}^{(t)})] \\Delta \\mathbf{x}.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent\n",
    "\n",
    "- If we use the identity matrix as a very crude approximation of the Hessian matrix, we obtain the classical **gradient descent**, or **steepest descent**, algorithm:\n",
    "$$\n",
    "\\mathbf{x}^{(t+1)} = \\mathbf{x}^{(t)} - s^{(t)} \\nabla f(\\mathbf{x}^{(t)}).\n",
    "$$\n",
    "\n",
    "- Gradient descent algorithm is gaining tremendous of interest in modern, large scale optimization problems, because calculation of Hessian is usually quite expensive. \n",
    "\n",
    "- Example: minimize a bivariate quadratic function:\n",
    "$$\n",
    "f(x_1, x_2) = \\frac 12 (x_1^2 + bx_2^2).\n",
    "$$\n",
    "Gradient:\n",
    "$$\n",
    "\\nabla f(x_1, x_2) = \\begin{pmatrix} x_1 \\\\ bx_2 \\end{pmatrix}.\n",
    "$$\n",
    "Gradient descent algorithm:\n",
    "\\begin{eqnarray*}\n",
    "\\begin{pmatrix} x_1^{(t+1)} \\\\ x_2^{(t+1)} \\end{pmatrix} &=& \\begin{pmatrix} x_1^{(t)} \\\\ x_2^{(t)} \\end{pmatrix} - s^{(t)} \\begin{pmatrix} x_1^{(t)} \\\\ bx_2^{(t)} \\end{pmatrix} \\\\\n",
    "&=& \\begin{pmatrix} (1 - s^{(t)}) x_1^{(t)} \\\\ (1 - bs^{(t)})x_2^{(t)} \\end{pmatrix}.\n",
    "\\end{eqnarray*}\n",
    "What's the optimal step length $s$ (exact line search)? The objective function\n",
    "$$\n",
    "f(s) = \\frac 12 \\left[(1-s)^2 x_1^{(t)2} + b(1-bs)^2x_2^{(t)2} \\right]\n",
    "$$\n",
    "is minimized at\n",
    "$$\n",
    "s^{(t)} = \\frac{x_1^{(t)2} + b^2 x_2^{(t)2}}{x_1^{(t)2} + b^3 x_2^{(t)2}}.\n",
    "$$\n",
    "Let's assume starting point $(x_1^{(0)}, x_2^{(0)}) = (b, 1)$ to simplify analysis. Then\n",
    "$$\n",
    "s^{(0)} = \\frac{b^2 + b^2}{b^2 + b^3} = \\frac{2}{b + 1}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "\\begin{pmatrix} x_1^{(1)} \\\\ x_2^{(1)} \\end{pmatrix} = \\begin{pmatrix} \\left( \\frac{b-1}{b+1} \\right) x_1^{(1)} \\\\ \\left( \\frac{1-b}{b+1} \\right) x_2^{(1)} \\end{pmatrix} = \\begin{pmatrix} b \\left( \\frac{b-1}{b+1} \\right) \\\\ \\left( \\frac{1-b}{b+1} \\right) \\end{pmatrix}.\n",
    "$$\n",
    "Continuing this way, we found\n",
    "$$\n",
    "\\begin{pmatrix} x_1^{(t)} \\\\ x_2^{(t)} \\end{pmatrix} = \\begin{pmatrix} b \\left( \\frac{b-1}{b+1} \\right)^t \\\\ \\left( \\frac{1-b}{b+1} \\right)^t \\end{pmatrix}\n",
    "$$\n",
    "and\n",
    "$$\n",
    "f(x_1^{(t)}, x_2^{(t)}) = \\frac 12 (1 + b^2) \\left( \\frac{b-1}{b+1} \\right)^{2t} = \\left( \\frac{b-1}{b+1} \\right)^{2t} f(x_1^{(0)}, x_2^{(0)}).\n",
    "$$\n",
    "\n",
    "    Following graph shows the zig-zagging pattern of the gradient descent iterates:  \n",
    "<img src=\"./gd.gif\" width=600 align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Recompiling stale cache file /Users/huazhou/.julia/compiled/v1.2/Plots/ld3vC.ji for Plots [91a5bcdd-55d7-5caf-9e0b-520d859cae80]\n",
      "└ @ Base loading.jl:1240\n"
     ]
    }
   ],
   "source": [
    "using Plots; gr()\n",
    "using LaTeXStrings\n",
    "\n",
    "b = 0.1\n",
    "f(x1, x2) = 0.5 * (x1^2 + b * x2^2)\n",
    "s = 2 / (1 + b) # optimal step length\n",
    "x1, x2 = b, 1.0   # start point\n",
    "x1iter, x2iter, fiter = [x1], [x2], [f(x1, x2)]  # store function values\n",
    "for iter in 1:15\n",
    "    x1 *= (1 - s)\n",
    "    x2 *= (1 - s * b)\n",
    "    push!(x1iter, x1)\n",
    "    push!(x2iter, x2)\n",
    "    push!(fiter, f(x1, x2))\n",
    "end\n",
    "\n",
    "x1 = -1:0.01:1\n",
    "x2 = -1:0.01:1\n",
    "X1 = repeat(reshape(x1, 1, :), length(x2), 1)\n",
    "X2 = repeat(x2, 1, length(x1))\n",
    "Z = map(f, X1, X2)\n",
    "p = contour(x1, x2, Z, levels=fiter)\n",
    "plot(p, xlabel=L\"x_1\", ylabel=L\"x_2\", title=\"GD\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Saved animation to \n",
      "│   fn = /Users/huazhou/Documents/github.com/ucla-biostat216-2019fall.github.io/slides/14-optim/gd.gif\n",
      "└ @ Plots /Users/huazhou/.julia/packages/Plots/AXUqs/src/animation.jl:98\n"
     ]
    }
   ],
   "source": [
    "anim = @animate for iter in 1:length(x1iter)-1\n",
    "    Plots.plot!(p, x1iter[iter:iter+1], x2iter[iter:iter+1], shape=:circle)\n",
    "    Plots.annotate!(p, x1iter[iter], x2iter[iter], text(latexstring(\"x^{($iter)}\"), :right))\n",
    "end\n",
    "gif(anim, \"./gd.gif\", fps = 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Above analysis can be generalized to a general **strongly convex** function that satisfies\n",
    "$$\n",
    "m \\mathbf{I}_n \\preceq \\nabla^2 f(\\mathbf{x}) \\preceq M \\mathbf{I}_n \\text{ for all } \\mathbf{x}\n",
    "$$\n",
    "for some constants $M > m > 0$. Or equivalently all eigenvalues of $\\nabla^2 f(\\mathbf{x})$ are in $[m, M]$.\n",
    "\n",
    "    Theorem: for any strongly convex function $f$, the gradient descent with exact line search satisfies\n",
    "$$\n",
    "f(\\mathbf{x}^{(t+1)}) - f(\\mathbf{x}^\\star) \\le \\left( 1 - \\frac mM \\right) [f(\\mathbf{x}^{(t)}) - f(\\mathbf{x}^\\star)],\n",
    "$$\n",
    "where $\\mathbf{x}^\\star$ is the optimum.\n",
    "\n",
    "- In practice, we often perform inexact line search such as backtracking, because exact line search is expensive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient descent with momentum\n",
    "\n",
    "- To mitigate the frustrating zig-zagging of gradient descent, Polyak proposed to add a **momentum** with coefficient $\\beta$ to the gradient. The idea is that a heavy ball rolling downhill has less zig-zagging.\n",
    "\n",
    "- **Gradient descent with momentum**:  \n",
    "\\begin{eqnarray*}\n",
    "    \\mathbf{x}^{(t+1)} &=& \\mathbf{x}^{(t)} - s \\mathbf{z}^{(t)} \\text{ with } \\\\\n",
    "    \\mathbf{z}^{(t)} &=& \\nabla f(\\mathbf{x}^{(t)}) + \\beta \\mathbf{z}^{(t-1)}.\n",
    "\\end{eqnarray*}\n",
    "\n",
    "- For a quadratic objective function\n",
    "$$\n",
    "f(\\mathbf{x}) = \\frac 12 \\mathbf{x}' \\mathbf{S} \\mathbf{x}.\n",
    "$$\n",
    "The optimal step length $s$ and  momentum coefficient $\\beta$ are given by (derivation omitted)\n",
    "\\begin{eqnarray*}\n",
    "s = \\left( \\frac{2}{\\sqrt{\\lambda_{\\text{max}}} +  \\sqrt{\\lambda_{\\text{min}}}} \\right)^2 \\\\\n",
    "\\beta = \\left( \\frac{\\sqrt{\\lambda_{\\text{max}}} -  \\sqrt{\\lambda_{\\text{min}}}}{\\sqrt{\\lambda_{\\text{max}}} +  \\sqrt{\\lambda_{\\text{min}}}} \\right)^2,\n",
    "\\end{eqnarray*}\n",
    "where $\\lambda_{\\text{min}}$ and $\\lambda_{\\text{max}}$ are the minimum and maximum eigenvalues of $\\mathbf{S}$.\n",
    "\n",
    "- Back to our 2-dimensional example $f(x_1, x_2) = \\frac 12 (x_1^2 + b x_2^2)$. We have\n",
    "$$\n",
    "s = \\left( \\frac{2}{1+\\sqrt b} \\right)^2, \\quad \\beta = \\left( \\frac{1 - \\sqrt b}{1 + \\sqrt b} \\right)^2,\n",
    "$$\n",
    "and\n",
    "$$\n",
    "f(x_1^{(t)}, x_2^{(t)}) = \\left( \\frac{1 - \\sqrt b}{1 + \\sqrt b} \\right)^{2t} f(x_1^{(0)}, x_2^{(0)}).\n",
    "$$\n",
    "The convergence rate improves from $\\left( \\frac{1 - b}{1 + b} \\right)^{2}$ to $\\left( \\frac{1 - \\sqrt b}{1 + \\sqrt b} \\right)^{2}$.\n",
    "\n",
    "    Following graph shows the iterates of gradient descent with momentum:  \n",
    "<img src=\"./gd_momentum.gif\" width=600 align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 0.1\n",
    "f(x1, x2) = 0.5 * (x1^2 + b * x2^2)\n",
    "s = (2 / (1 + sqrt(b)))^2             # optimal step length\n",
    "β = ((1 - sqrt(b)) / (1 + sqrt(b)))^2 # optimal momentum coefficient\n",
    "x1, x2 = b, 1.0   # start point\n",
    "z1, z2 = [0.0, 0.0]\n",
    "x1iter, x2iter, fiter = [x1], [x2], [f(x1, x2)]  # store function values\n",
    "for iter in 1:15\n",
    "    z1 = x1 + β * z1\n",
    "    z2 = b * x2 + β * z2\n",
    "    x1 -= s * z1\n",
    "    x2 -= s * z2\n",
    "    push!(x1iter, x1)\n",
    "    push!(x2iter, x2)\n",
    "    push!(fiter, f(x1, x2))\n",
    "end\n",
    "\n",
    "x1 = -1:0.01:1\n",
    "x2 = -1:0.01:1\n",
    "X1 = repeat(reshape(x1, 1, :), length(x2), 1)\n",
    "X2 = repeat(x2, 1, length(x1))\n",
    "Z = map(f, X1, X2)\n",
    "p = contour(x1, x2, Z, levels=fiter)\n",
    "plot(p, xlabel=L\"x_1\", ylabel=L\"x_2\", title=\"GD with Momentum\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Saved animation to \n",
      "│   fn = /Users/huazhou/Documents/github.com/ucla-biostat216-2019fall.github.io/slides/14-optim/gd_momentum.gif\n",
      "└ @ Plots /Users/huazhou/.julia/packages/Plots/AXUqs/src/animation.jl:98\n"
     ]
    }
   ],
   "source": [
    "anim = @animate for iter in 1:length(x1iter)-1\n",
    "    Plots.plot!(p, x1iter[iter:iter+1], x2iter[iter:iter+1], shape=:circle)\n",
    "    Plots.annotate!(p, x1iter[iter], x2iter[iter], text(latexstring(\"x^{($iter)}\"), :right))\n",
    "end\n",
    "gif(anim, \"./gd_momentum.gif\", fps = 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nesterov acceleration of gradient descent\n",
    "\n",
    "- Yuri Nesterov proposed that, instead of evaluating the gradient $\\nabla f$ at current iterate $\\mathbf{x}^{(t)}$, we shift the evaluation point to $\\mathbf{x}^{(t)} + \\gamma (\\mathbf{x}^{(t)} - \\mathbf{x}^{(t-1)})$.\n",
    "\n",
    "- **Nesetrov accelerated gradient descent**\n",
    "\\begin{eqnarray*}\n",
    "\\mathbf{x}^{(t+1)} &=& \\mathbf{x}^{(t)} - s \\nabla f(\\mathbf{y}^{(t)}) \\\\\n",
    "\\mathbf{y}^{(t+1)} &=& \\mathbf{x}^{(t+1)} + \\gamma (\\mathbf{x}^{(t+1)} - \\mathbf{x}^{(t)}).\n",
    "\\end{eqnarray*}\n",
    "\n",
    "- For a quadratic objective function\n",
    "$$\n",
    "f(\\mathbf{x}) = \\frac 12 \\mathbf{x}' \\mathbf{S} \\mathbf{x}.\n",
    "$$\n",
    "The optimal step length $s$ and $\\gamma$ are given by (derivation omitted)\n",
    "\\begin{eqnarray*}\n",
    "s &=& \\frac{1}{\\lambda_{\\text{max}}} \\\\\n",
    "\\gamma &=& \\frac{\\sqrt{\\lambda_{\\text{max}}} -  \\sqrt{\\lambda_{\\text{min}}}}{\\sqrt{\\lambda_{\\text{max}}} +  \\sqrt{\\lambda_{\\text{min}}}},\n",
    "\\end{eqnarray*}\n",
    "where $\\lambda_{\\text{min}}$ and $\\lambda_{\\text{max}}$ are the minimum and maximum eigenvalues of $\\mathbf{S}$.\n",
    "\n",
    "- The convergence rate improves from $\\left( \\frac{1 - b}{1 + b} \\right)^{2}$ to $1 - \\sqrt b$.\n",
    "\n",
    "<img src=\"./gd_nesterov.gif\" width=600 align=\"center\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = 0.1\n",
    "f(x1, x2) = 0.5 * (x1^2 + b * x2^2)\n",
    "s = 1.0                           # optimal step length\n",
    "γ = (1 - sqrt(b)) / (1 + sqrt(b)) # optimal Nesterov constant\n",
    "x1, x2 = b, 1.0   # start point\n",
    "y1, y2 = x1, x2\n",
    "x1iter, x2iter, fiter = [x1], [x2], [f(x1, x2)]  # store iterates\n",
    "for iter in 1:15\n",
    "    x1prev, x2prev = x1, x2\n",
    "    x1 = y1 - s * y1\n",
    "    x2 = y2 - s * b * y2\n",
    "    y1 = x1 + γ * (x1 - x1prev)\n",
    "    y2 = x2 + γ * (x2 - x2prev)\n",
    "    push!(x1iter, x1)\n",
    "    push!(x2iter, x2)\n",
    "    push!(fiter, f(x1, x2))\n",
    "end\n",
    "\n",
    "x1 = -1:0.01:1\n",
    "x2 = -1:0.01:1\n",
    "X1 = repeat(reshape(x1, 1, :), length(x2), 1)\n",
    "X2 = repeat(x2, 1, length(x1))\n",
    "Z = map(f, X1, X2)\n",
    "p = contour(x1, x2, Z, levels=fiter)\n",
    "plot(p, xlabel=L\"x_1\", ylabel=L\"x_2\", title=\"GD with Nesterov\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "┌ Info: Saved animation to \n",
      "│   fn = /Users/huazhou/Documents/github.com/ucla-biostat216-2019fall.github.io/slides/14-optim/gd_nesterov.gif\n",
      "└ @ Plots /Users/huazhou/.julia/packages/Plots/AXUqs/src/animation.jl:98\n"
     ]
    }
   ],
   "source": [
    "anim = @animate for iter in 1:length(x1iter)-1\n",
    "    Plots.plot!(p, x1iter[iter:iter+1], x2iter[iter:iter+1], shape=:circle)\n",
    "    Plots.annotate!(p, x1iter[iter], x2iter[iter], text(latexstring(\"x^{($iter)}\"), :right))\n",
    "end\n",
    "gif(anim, \"./gd_nesterov.gif\", fps = 1);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stochastic gradient descent\n",
    "\n",
    "- In machine learning and statistics, we need to minimize the loss function of training data\n",
    "$$\n",
    "L(\\mathbf{x}) = \\frac 1N \\sum_{i=1}^N \\ell(\\mathbf{x}, \\mathbf{v}_i),\n",
    "$$\n",
    "where $\\mathbf{x}$ is the parameter to be fitted, $N$ is the training sample size, and $\\mathbf{v}_i$ is the $i$-th sample.\n",
    "\n",
    "    For example, in leasts squares problem, we minimize\n",
    "$$\n",
    "L(\\mathbf{x}) = \\frac 1N \\|\\mathbf{b} - \\mathbf{A} \\mathbf{x}\\|^2 = \\frac 1N \\sum_{i=1}^N (b_i - \\mathbf{a}_i' x)^2.\n",
    "$$\n",
    "\n",
    "- Issues of the (classical) gradient descent scheme\n",
    "$$\n",
    "\\mathbf{x}^{(t+1)} = \\mathbf{x}^{(t)} - s^{(t)} \\nabla L(\\mathbf{x}).\n",
    "$$\n",
    "include:  \n",
    "    1. Evaluating $\\nabla L(\\mathbf{x}) = \\frac 1N \\sum_{i=1}^N \\nabla \\ell(\\mathbf{x}, \\mathbf{v}_i)$ can be expensive when $N$ is large.  \n",
    "    2. The solution found by gradient descent does not generalize well on the test data.  \n",
    "    \n",
    "- The **stochastic gradient descent** uses only a mini-batch (of size $B$) of the training data at each step:  \n",
    "$$\n",
    "\\mathbf{x}^{(t+1)} = \\mathbf{x}^{(t)} - s^{(t)} \\frac{1}{B} \\sum_{i \\in \\text{mini-batch}} \\nabla \\ell(\\mathbf{x}, \\mathbf{v}_i).\n",
    "$$\n",
    "\n",
    "- Stochastic gradient descent solves the two issues of gradient descent. It is the workhorse in deep learning."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.2.0",
   "language": "julia",
   "name": "julia-1.2"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.2.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
